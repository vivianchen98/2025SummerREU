# Final Reflection

## What Have We Really Been Studying?

You’ve implemented a range of decision-making algorithms: 
DFS, BFS, Value Iteration, Q-learning, Approximate Q-learning...

But step back — what do these all have in common?

> Take a moment to reflect:  
> **What is the *core problem* all these algorithms are trying to solve?**

---

## The Common Thread

At the heart of all these methods is this simple question:

> **"What action should an agent take in a given situation?"**

Every algorithm we’ve studied is a different way of answering that — depending on what the agent *knows*, and *how it interacts* with the environment.

---
## Big Ideas Across Algorithms

1. **Is the environment deterministic or stochastic?**
   - Does taking the same action always lead to the same result, or can outcomes vary?

2. **Does the agent know how the world works?**
   - Does it have a model of the environment (transitions, rewards), allowing it to plan ahead using that knowledge?

3. **Does the agent learn from experience?**
   - Does it improve its decisions by interacting with the environment, or does it plan everything in advance?

4. **Does the agent generalize across states?**
   - Can it apply what it learns in one situation to new, unseen situations?

---

## ✏️ Exercise 1: Thinking Like a Researcher

This is how research works:  
**Build → Hit a wall → Ask a better question → Build again.**

Let’s reflect on the evolution of the algorithms we’ve studied:  
**Search, MDPs, Value Iteration, Q-Learning, Approximate Q-Learning**

Your task is to trace the progression behind these ideas:

> **How did each approach advance our ability to make decisions?**  
> – What specific challenge did it address?  
> – What new limitation or question did it reveal?  
> – How did the next method build on or overcome these issues?

---

## ✏️ Exercise 2: Connecting to the Real World

Pick any **real-world decision-making system** you’re interested in —  
a robot, a game AI, a recommender, a smart assistant…

> Can you spot any ideas from this project that connect to how it might work?

(No need for a perfect answer — just think and explore.)